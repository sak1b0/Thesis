{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lets_get_it_done.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sak1b0/Thesis/blob/master/lets_get_it_done.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0UYUeyFtIL",
        "colab_type": "code",
        "outputId": "3d0904e5-01e4-41b6-d9e0-38114a01e9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "#import pylab as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url='https://raw.githubusercontent.com/sak1b0/Thesis/master/allCSV/letter.csv'\n",
        "\n",
        "df=pd.read_csv(url,header=None)\n",
        "#print(df.iloc[0,:])\n",
        "\n",
        "\n",
        "#----------to handle nominal values---------\n",
        "\n",
        "my_arr=[]\n",
        "\n",
        "#track of column indices \n",
        "index=0\n",
        "for item in df.dtypes:\n",
        "  if(item=='object'):\n",
        "    #if data type is nominal adding to the array\n",
        "    my_arr.append(index)\n",
        "  index=index+1\n",
        "  \n",
        "print('object data types: ',len(my_arr))\n",
        "\n",
        "df=df.values\n",
        "\n",
        "if(len(my_arr)>0):\n",
        "  lbl=LabelEncoder()\n",
        "  for item in my_arr:\n",
        "    df[:,item] = lbl.fit_transform(df[:,item])\n",
        "    \n",
        "  print('after the conversion: ',df[0])    \n",
        "#--------------------------------------------\n",
        "\n",
        "\n",
        "df=np.asarray(df)\n",
        "\n",
        "X, y = np.split(df,[-1],axis=1)\n",
        "#issue here !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "y=y.astype('float64')\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.005,random_state=101)\n",
        "\n",
        "#to check additional info \n",
        "debug=0\n",
        "\n",
        "def debug_me():\n",
        "  print('----------debug start----------')\n",
        "  print('main data: ',df.shape)\n",
        "  print('x: ',X.shape)\n",
        "  print('y: ',y.shape)\n",
        "  print('x_train: ',x_train.shape)\n",
        "  print('x_test: ',x_test.shape)\n",
        "  print('y_train: ',y_train.shape)\n",
        "  print('y_test: ',y_test.shape)\n",
        "  print('----------debug end----------')\n",
        "\n",
        "\n",
        "\n",
        "X=np.asarray(X)\n",
        "y=np.asarray(y)\n",
        "# y=y.ravel() #vector to array\n",
        "\n",
        "x_train=np.asarray(x_train)\n",
        "x_test=np.asarray(x_test)\n",
        "y_train=np.asarray(y_train)\n",
        "y_test=np.asarray(y_test)\n",
        "\n",
        "y_train=y_train.ravel()\n",
        "y_test=y_test.ravel()\n",
        "\n",
        "debug_me()\n",
        "#==========preprocessing done============\n",
        "\n",
        "\n",
        "#==========optimal number of clusters====\n",
        "\n",
        "\n",
        "no_of_features=x_train.shape[1]\n",
        "optimal_k=len(np.unique(y_train))\n",
        "#print('no of features: ',no_of_features)\n",
        "#print('actual no of classes: ',optimal_k)\n",
        "#plt.figure(figsize=(6, 4))\n",
        "#from sklearn.cluster import KMeans\n",
        "#wcss = []\n",
        "#for i in range(1, no_of_features):\n",
        "#    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 101)\n",
        "#    kmeans.fit(x_train)\n",
        "#    wcss.append(kmeans.inertia_)\n",
        "#plt.plot(range(1, no_of_features), wcss)\n",
        "#plt.title('The Elbow Method')\n",
        "#plt.xlabel('Number of clusters')\n",
        "#plt.ylabel('WCSS')\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "#=================experiment===========\n",
        "print(\"optimal no. of k = \",optimal_k,'\\n')\n",
        "\n",
        "kmeans = KMeans(n_clusters=optimal_k, init = 'k-means++', random_state= 101)\n",
        "\n",
        "kmeans.fit(x_train)\n",
        "\n",
        "#print(kmeans.cluster_centers_)  \n",
        "\n",
        "print('cluster labels: ',kmeans.labels_[0:5,],'\\n')\n",
        "\n",
        "#creating an array as the index to add column to the main df\n",
        "ind_arr=np.arange(len(x_train))\n",
        "\n",
        "#adding the index column to the data so that i can understand later\n",
        "x_train=np.hstack((ind_arr[:, np.newaxis], x_train))\n",
        "\n",
        "#to see if it has worked and index column is there or not\n",
        "#print(pd.DataFrame(x_train[:5,]),'\\n')\n",
        "##print(x_train[:5,],'\\n')\n",
        "\n",
        "##print('-- first column is index --')\n",
        "#print(pd.DataFrame(x_train[:5,]),'\\n')\n",
        "##print(x_train[:5,],'\\n')\n",
        "\n",
        "#print(pd.DataFrame(x_train[:5,1:-1]),'\\n')\n",
        "##print(x_train[:5,1:-1],'\\n') #without the index here\n",
        "\n",
        "#mergning y(actual labels with x again)\n",
        "##print(len(x_train))\n",
        "##print(len(y_train))\n",
        "#np arrays have to be in the proper shape to be appended\n",
        "y_train = y_train.reshape((y_train.shape[0], 1))\n",
        "##print(x_train.shape)\n",
        "##print(y_train.shape)\n",
        "x_train=np.append(x_train,y_train, axis=1)\n",
        "##print(x_train[:5,])\n",
        "\n",
        "##print(kmeans.labels_.shape)\n",
        "cluster_labels = np.asarray(kmeans.labels_)\n",
        "cluster_labels = cluster_labels.reshape((cluster_labels.shape[0], 1))\n",
        "##print(cluster_labels.shape)\n",
        "\n",
        "#adding the cluster label column to the data in the last column\n",
        "train_data=np.append(x_train,cluster_labels, axis=1)\n",
        "#print('basic train data',train_data[:5])\n",
        "\n",
        "############### working in office lol #####################\n",
        "print('my train_data_size: ',train_data.shape)\n",
        "cluster_number, occur_count = np.unique(train_data[:,-1], return_counts=True)\n",
        " \n",
        "print(\"Cluster No: \" , cluster_number)\n",
        "print(\"Instance Count : \", occur_count)\n",
        "\n",
        "#for i in range(len(cluster_number)):\n",
        "  #print('Cluster: '+str(cluster_number[i])+' :'+str(occur_count[i]))\n",
        "  \n",
        "#should not miss these 2 lines and not in the loop\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "y_test = y_test.ravel()\n",
        " \n",
        "model = GaussianNB()\n",
        "\n",
        "#all the predictions of different models will be saved in votes\n",
        "votes = []\n",
        "weights = []\n",
        "\n",
        "for index in range(len(cluster_number)):\n",
        "  print('==================','working with cluster: ',index, '==================')\n",
        "  sub_train_data = train_data[train_data[:,-1] == cluster_number[index]]\n",
        "  #print('sub data size: ',len(sub_train_data))  #to see if the sub data is selected propoerly\n",
        "  #print(sub_train_data[0:3,:],'\\n')\n",
        "  sub_train_data = sub_train_data[:,1:-1]  #index column and last cluster column \n",
        "  #print(sub_train_data[0:3,:],'\\n')\n",
        "  sub_train_x, sub_train_y = np.split(sub_train_data,[-1],axis=1)\n",
        "  #display(sub_train_x[0:3,:])\n",
        "  #display(sub_train_y[0:3,:])\n",
        "\n",
        "  #converting the y to float\n",
        "  sub_train_y = sub_train_y.astype('float64')\n",
        "\n",
        "  sub_train_x = np.asarray(sub_train_x)\n",
        "  sub_train_y = np.asarray(sub_train_y)\n",
        "  sub_train_y = sub_train_y.ravel()\n",
        "\n",
        "  model.fit(sub_train_x,sub_train_y) #train\n",
        "\n",
        "  expected = y_test\n",
        "  predicted = model.predict(x_test)\n",
        "  print('predicted: ',predicted[0:5])\n",
        "  print('expected: ',expected[0:5])\n",
        "  acc_score = round(accuracy_score(expected, predicted, normalize=True),5)\n",
        "  votes.append(predicted)\n",
        "  weights.append(acc_score)\n",
        "  \n",
        "  print('\\nAccuracy: ',acc_score,'\\n')\n",
        "  #print(metrics.classification_report(expected, predicted))\n",
        "  \n",
        "  #print('============================== DONE ================================\\n')\n",
        "\n",
        "votes=np.asarray(votes)\n",
        "print(votes.shape)\n",
        "for i in range(len(votes)):\n",
        "  print(votes[i][0:10], ' weight: ',weights[i])\n",
        "\n",
        "print('=========================================================')\n",
        "print(expected[0:10])\n",
        "\n",
        "\n",
        "###########################################################\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object data types:  1\n",
            "after the conversion:  [2 4 4 3 2 7 8 2 9 11 7 7 1 8 5 6 25]\n",
            "----------debug start----------\n",
            "main data:  (20000, 17)\n",
            "x:  (20000, 16)\n",
            "y:  (20000, 1)\n",
            "x_train:  (19900, 16)\n",
            "x_test:  (100, 16)\n",
            "y_train:  (19900,)\n",
            "y_test:  (100,)\n",
            "----------debug end----------\n",
            "optimal no. of k =  26 \n",
            "\n",
            "cluster labels:  [11 18 10 11  3] \n",
            "\n",
            "my train_data_size:  (19900, 19)\n",
            "Cluster No:  [0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25]\n",
            "Instance Count :  [ 214  972  580 1181  903 1176  749  620 1396  581  863 1179  490  536\n",
            "  331  589 1035  458  920  678  701  772 1511  588  703  174]\n",
            "================== working with cluster:  0 ==================\n",
            "predicted:  [9. 9. 9. 9. 9.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.02 \n",
            "\n",
            "================== working with cluster:  1 ==================\n",
            "predicted:  [20. 24. 18. 18. 19.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.22 \n",
            "\n",
            "================== working with cluster:  2 ==================\n",
            "predicted:  [15. 15. 15.  5. 15.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.11 \n",
            "\n",
            "================== working with cluster:  3 ==================\n",
            "predicted:  [ 8.  8. 18.  9.  9.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.23 \n",
            "\n",
            "================== working with cluster:  4 ==================\n",
            "predicted:  [16. 16. 16. 16. 13.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.17 \n",
            "\n",
            "================== working with cluster:  5 ==================\n",
            "predicted:  [ 6. 16.  9.  9. 24.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.15 \n",
            "\n",
            "================== working with cluster:  6 ==================\n",
            "predicted:  [ 5. 15.  5.  5. 22.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.16 \n",
            "\n",
            "================== working with cluster:  7 ==================\n",
            "predicted:  [22. 21. 21. 13. 22.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.14 \n",
            "\n",
            "================== working with cluster:  8 ==================\n",
            "predicted:  [16. 15.  6. 20. 20.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.24 \n",
            "\n",
            "================== working with cluster:  9 ==================\n",
            "predicted:  [12. 12. 12. 12. 12.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.06 \n",
            "\n",
            "================== working with cluster:  10 ==================\n",
            "predicted:  [18.  2.  4. 17. 13.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.17 \n",
            "\n",
            "================== working with cluster:  11 ==================\n",
            "predicted:  [ 9. 15. 18. 17. 13.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.19 \n",
            "\n",
            "================== working with cluster:  12 ==================\n",
            "predicted:  [13. 13. 12. 12. 12.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.06 \n",
            "\n",
            "================== working with cluster:  13 ==================\n",
            "predicted:  [2. 2. 6. 2. 2.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.07 \n",
            "\n",
            "================== working with cluster:  14 ==================\n",
            "predicted:  [11. 11. 11. 11. 11.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.02 \n",
            "\n",
            "================== working with cluster:  15 ==================\n",
            "predicted:  [25. 25.  4. 23.  4.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.05 \n",
            "\n",
            "================== working with cluster:  16 ==================\n",
            "predicted:  [16.  2.  6. 17. 18.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.19 \n",
            "\n",
            "================== working with cluster:  17 ==================\n",
            "predicted:  [21. 21. 21. 19. 22.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.09 \n",
            "\n",
            "================== working with cluster:  18 ==================\n",
            "predicted:  [24. 15. 25. 24. 24.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.14 \n",
            "\n",
            "================== working with cluster:  19 ==================\n",
            "predicted:  [ 0.  0.  0.  0. 12.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.07 \n",
            "\n",
            "================== working with cluster:  20 ==================\n",
            "predicted:  [21. 21. 21. 21. 21.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.05 \n",
            "\n",
            "================== working with cluster:  21 ==================\n",
            "predicted:  [20. 22. 13. 20. 22.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.14 \n",
            "\n",
            "================== working with cluster:  22 ==================\n",
            "predicted:  [16. 15.  6. 17. 16.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.35 \n",
            "\n",
            "================== working with cluster:  23 ==================\n",
            "predicted:  [ 9.  9. 11. 11.  9.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.06 \n",
            "\n",
            "================== working with cluster:  24 ==================\n",
            "predicted:  [ 5.  5.  5.  5. 24.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.13 \n",
            "\n",
            "================== working with cluster:  25 ==================\n",
            "predicted:  [20. 20. 20. 20. 20.]\n",
            "expected:  [16. 15. 18. 17. 22.]\n",
            "\n",
            "Accuracy:  0.02 \n",
            "\n",
            "(26, 100)\n",
            "[9. 9. 9. 9. 9. 9. 9. 9. 9. 9.]  weight:  0.02\n",
            "[20. 24. 18. 18. 19. 18. 19. 20. 24. 20.]  weight:  0.22\n",
            "[15. 15. 15.  5. 15. 24. 15. 15.  5. 15.]  weight:  0.11\n",
            "[ 8.  8. 18.  9.  9.  8.  8.  8.  8.  8.]  weight:  0.23\n",
            "[16. 16. 16. 16. 13. 13. 20. 20. 12. 16.]  weight:  0.17\n",
            "[ 6. 16.  9.  9. 24.  1. 24. 24. 15. 16.]  weight:  0.15\n",
            "[ 5. 15.  5.  5. 22.  5.  5. 20.  5.  5.]  weight:  0.16\n",
            "[22. 21. 21. 13. 22. 21. 22. 21.  7. 21.]  weight:  0.14\n",
            "[16. 15.  6. 20. 20. 20. 20. 20. 20. 14.]  weight:  0.24\n",
            "[12. 12. 12. 12. 12. 12. 12. 22. 22. 22.]  weight:  0.06\n",
            "[18.  2.  4. 17. 13.  9. 18. 18.  1.  2.]  weight:  0.17\n",
            "[ 9. 15. 18. 17. 13.  7.  9.  9.  1.  9.]  weight:  0.19\n",
            "[13. 13. 12. 12. 12. 13. 12. 12. 12. 12.]  weight:  0.06\n",
            "[2. 2. 6. 2. 2. 2. 2. 2. 6. 6.]  weight:  0.07\n",
            "[11. 11. 11. 11. 11. 11. 11. 11. 11. 11.]  weight:  0.02\n",
            "[25. 25.  4. 23.  4. 25.  4. 25. 25.  4.]  weight:  0.05\n",
            "[16.  2.  6. 17. 18.  6. 16. 20.  6.  6.]  weight:  0.19\n",
            "[21. 21. 21. 19. 22. 19. 19. 20. 19. 21.]  weight:  0.09\n",
            "[24. 15. 25. 24. 24. 25. 24. 24.  1. 16.]  weight:  0.14\n",
            "[ 0.  0.  0.  0. 12.  0.  0.  0.  0.  0.]  weight:  0.07\n",
            "[21. 21. 21. 21. 21. 21. 19. 21. 21. 21.]  weight:  0.05\n",
            "[20. 22. 13. 20. 22. 13. 20. 20. 22. 20.]  weight:  0.14\n",
            "[16. 15.  6. 17. 16. 15. 20. 20. 15. 16.]  weight:  0.35\n",
            "[ 9.  9. 11. 11.  9.  9.  9.  9. 11.  8.]  weight:  0.06\n",
            "[ 5.  5.  5.  5. 24. 19. 24. 24. 24. 24.]  weight:  0.13\n",
            "[20. 20. 20. 20. 20. 20. 20. 20. 20. 20.]  weight:  0.02\n",
            "=========================================================\n",
            "[16. 15. 18. 17. 22. 24. 19. 20. 18. 16.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NhWy_610H6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr=np.array([[77,77,77,1],[55,55,55,2],[88,88,88,2],[44,44,44,3]])\n",
        "print(pd.DataFrame(arr))\n",
        "arr=np.split(arr, np.where(np.diff(arr[:,-1]))[0]+1)\n",
        "print(pd.DataFrame(arr))\n",
        "print('no of sub arrays: ',len(arr))\n",
        "print(arr[1][0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}