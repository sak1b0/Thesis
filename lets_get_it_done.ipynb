{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lets_get_it_done.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sak1b0/Thesis/blob/master/lets_get_it_done.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0UYUeyFtIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "#import pylab as pl\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url='https://raw.githubusercontent.com/sak1b0/Thesis/master/allCSV/letter.csv'\n",
        "\n",
        "df=pd.read_csv(url,header=None)\n",
        "#print(df.iloc[0,:])\n",
        "\n",
        "\n",
        "#----------to handle nominal values---------\n",
        "\n",
        "my_arr=[]\n",
        "\n",
        "#track of column indices \n",
        "index=0\n",
        "for item in df.dtypes:\n",
        "  if(item=='object'):\n",
        "    #if data type is nominal adding to the array\n",
        "    my_arr.append(index)\n",
        "  index=index+1\n",
        "  \n",
        "print('object data types: ',len(my_arr))\n",
        "\n",
        "df=df.values\n",
        "\n",
        "if(len(my_arr)>0):\n",
        "  lbl=LabelEncoder()\n",
        "  for item in my_arr:\n",
        "    df[:,item] = lbl.fit_transform(df[:,item])\n",
        "    \n",
        "  print('after the conversion: ',df[0])    \n",
        "#--------------------------------------------\n",
        "\n",
        "\n",
        "df=np.asarray(df)\n",
        "\n",
        "X, y = np.split(df,[-1],axis=1)\n",
        "#issue here !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "y=y.astype('float64')\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.005,random_state=101)\n",
        "\n",
        "#to check additional info \n",
        "debug=0\n",
        "\n",
        "def debug_me():\n",
        "  print('----------debug start----------')\n",
        "  print('main data: ',df.shape)\n",
        "  print('x: ',X.shape)\n",
        "  print('y: ',y.shape)\n",
        "  print('x_train: ',x_train.shape)\n",
        "  print('x_test: ',x_test.shape)\n",
        "  print('y_train: ',y_train.shape)\n",
        "  print('y_test: ',y_test.shape)\n",
        "  print('----------debug end----------')\n",
        "\n",
        "\n",
        "\n",
        "X=np.asarray(X)\n",
        "y=np.asarray(y)\n",
        "# y=y.ravel() #vector to array\n",
        "\n",
        "x_train=np.asarray(x_train)\n",
        "x_test=np.asarray(x_test)\n",
        "y_train=np.asarray(y_train)\n",
        "y_test=np.asarray(y_test)\n",
        "\n",
        "y_train=y_train.ravel()\n",
        "y_test=y_test.ravel()\n",
        "\n",
        "debug_me()\n",
        "#==========preprocessing done============\n",
        "\n",
        "\n",
        "#==========optimal number of clusters====\n",
        "\n",
        "\n",
        "no_of_features=x_train.shape[1]\n",
        "optimal_k=len(np.unique(y_train))\n",
        "#print('no of features: ',no_of_features)\n",
        "#print('actual no of classes: ',optimal_k)\n",
        "#plt.figure(figsize=(6, 4))\n",
        "#from sklearn.cluster import KMeans\n",
        "#wcss = []\n",
        "#for i in range(1, no_of_features):\n",
        "#    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 101)\n",
        "#    kmeans.fit(x_train)\n",
        "#    wcss.append(kmeans.inertia_)\n",
        "#plt.plot(range(1, no_of_features), wcss)\n",
        "#plt.title('The Elbow Method')\n",
        "#plt.xlabel('Number of clusters')\n",
        "#plt.ylabel('WCSS')\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "#=================experiment===========\n",
        "print(\"optimal no. of k = \",optimal_k,'\\n')\n",
        "\n",
        "kmeans = KMeans(n_clusters=optimal_k, init = 'k-means++', random_state= 101)\n",
        "\n",
        "kmeans.fit(x_train)\n",
        "\n",
        "#print(kmeans.cluster_centers_)  \n",
        "\n",
        "print('cluster labels: ',kmeans.labels_[0:5,],'\\n')\n",
        "\n",
        "#creating an array as the index to add column to the main df\n",
        "ind_arr=np.arange(len(x_train))\n",
        "\n",
        "#adding the index column to the data so that i can understand later\n",
        "x_train=np.hstack((ind_arr[:, np.newaxis], x_train))\n",
        "\n",
        "#to see if it has worked and index column is there or not\n",
        "#print(pd.DataFrame(x_train[:5,]),'\\n')\n",
        "##print(x_train[:5,],'\\n')\n",
        "\n",
        "##print('-- first column is index --')\n",
        "#print(pd.DataFrame(x_train[:5,]),'\\n')\n",
        "##print(x_train[:5,],'\\n')\n",
        "\n",
        "#print(pd.DataFrame(x_train[:5,1:-1]),'\\n')\n",
        "##print(x_train[:5,1:-1],'\\n') #without the index here\n",
        "\n",
        "#mergning y(actual labels with x again)\n",
        "##print(len(x_train))\n",
        "##print(len(y_train))\n",
        "#np arrays have to be in the proper shape to be appended\n",
        "y_train = y_train.reshape((y_train.shape[0], 1))\n",
        "##print(x_train.shape)\n",
        "##print(y_train.shape)\n",
        "x_train=np.append(x_train,y_train, axis=1)\n",
        "##print(x_train[:5,])\n",
        "\n",
        "##print(kmeans.labels_.shape)\n",
        "cluster_labels = np.asarray(kmeans.labels_)\n",
        "cluster_labels = cluster_labels.reshape((cluster_labels.shape[0], 1))\n",
        "##print(cluster_labels.shape)\n",
        "\n",
        "#adding the cluster label column to the data in the last column\n",
        "train_data=np.append(x_train,cluster_labels, axis=1)\n",
        "#print('basic train data',train_data[:5])\n",
        "\n",
        "############### working in office lol #####################\n",
        "print('my train_data_size: ',train_data.shape)\n",
        "cluster_number, occur_count = np.unique(train_data[:,-1], return_counts=True)\n",
        " \n",
        "print(\"Cluster No: \" , cluster_number)\n",
        "print(\"Instance Count : \", occur_count)\n",
        "\n",
        "#for i in range(len(cluster_number)):\n",
        "  #print('Cluster: '+str(cluster_number[i])+' :'+str(occur_count[i]))\n",
        "  \n",
        "#should not miss these 2 lines and not in the loop\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)\n",
        "y_test = y_test.ravel()\n",
        " \n",
        "model = GaussianNB()\n",
        "\n",
        "#all the predictions of different models will be saved in votes\n",
        "votes = []\n",
        "weights = []\n",
        "\n",
        "for index in range(len(cluster_number)):\n",
        "  print('==================','working with cluster: ',index, '==================')\n",
        "  sub_train_data = train_data[train_data[:,-1] == cluster_number[index]]\n",
        "  #print('sub data size: ',len(sub_train_data))  #to see if the sub data is selected propoerly\n",
        "  #print(sub_train_data[0:3,:],'\\n')\n",
        "  sub_train_data = sub_train_data[:,1:-1]  #index column and last cluster column \n",
        "  #print(sub_train_data[0:3,:],'\\n')\n",
        "  sub_train_x, sub_train_y = np.split(sub_train_data,[-1],axis=1)\n",
        "  #display(sub_train_x[0:3,:])\n",
        "  #display(sub_train_y[0:3,:])\n",
        "\n",
        "  #converting the y to float\n",
        "  sub_train_y = sub_train_y.astype('float64')\n",
        "\n",
        "  sub_train_x = np.asarray(sub_train_x)\n",
        "  sub_train_y = np.asarray(sub_train_y)\n",
        "  sub_train_y = sub_train_y.ravel()\n",
        "\n",
        "  model.fit(sub_train_x,sub_train_y) #train\n",
        "\n",
        "  expected = y_test\n",
        "  predicted = model.predict(x_test)\n",
        "  print('predicted: ',predicted[0:5])\n",
        "  print('expected: ',expected[0:5])\n",
        "  acc_score = round(accuracy_score(expected, predicted, normalize=True),5)\n",
        "  votes.append(predicted)\n",
        "  weights.append(acc_score)\n",
        "  \n",
        "  print('\\nAccuracy: ',acc_score,'\\n')\n",
        "  #print(metrics.classification_report(expected, predicted))\n",
        "  \n",
        "  #print('============================== DONE ================================\\n')\n",
        "\n",
        "votes=np.asarray(votes)\n",
        "print(votes.shape)\n",
        "for i in range(len(votes)):\n",
        "  print(votes[i][0:10], ' weight: ',weights[i])\n",
        "\n",
        "print('=========================================================')\n",
        "print(expected[0:10])\n",
        "\n",
        "\n",
        "###########################################################\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NhWy_610H6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr=np.array([[77,77,77,1],[55,55,55,2],[88,88,88,2],[44,44,44,3]])\n",
        "print(pd.DataFrame(arr))\n",
        "arr=np.split(arr, np.where(np.diff(arr[:,-1]))[0]+1)\n",
        "print(pd.DataFrame(arr))\n",
        "print('no of sub arrays: ',len(arr))\n",
        "print(arr[1][0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}